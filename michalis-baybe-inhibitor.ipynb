{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/baybe/telemetry.py:222: UserWarning: WARNING: BayBE Telemetry endpoint https://public.telemetry.baybe.p.uptimize.merckgroup.com:4317 cannot be reached. Disabling telemetry. The exception encountered was: ConnectionError, HTTPConnectionPool(host='verkehrsnachrichten.merck.de', port=80): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7fe4aff47c10>: Failed to resolve 'verkehrsnachrichten.merck.de' ([Errno -2] Name or service not known)\"))\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from baybe import Campaign\n",
    "from baybe.objective import Objective\n",
    "from baybe.parameters import NumericalDiscreteParameter, SubstanceParameter\n",
    "from baybe.recommenders import RandomRecommender, TwoPhaseMetaRecommender\n",
    "from baybe.searchspace import SearchSpace\n",
    "from baybe.simulation import simulate_scenarios\n",
    "from baybe.targets import NumericalTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKE_TEST = \"SMOKE_TEST\" in os.environ\n",
    "N_MC_ITERATIONS = 2 if SMOKE_TEST else 5\n",
    "N_DOE_ITERATIONS = 2 if SMOKE_TEST else 5\n",
    "BATCH_SIZE = 1 if SMOKE_TEST else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = pd.read_excel('data/filtered_AA2024.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SMILES = lookup.SMILES.unique()\n",
    "\n",
    "def list_to_dict(input_list):\n",
    "    return {item: item for item in input_list}\n",
    "\n",
    "smiles_dict =list_to_dict(unique_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.parameters import SubstanceParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "encoding_choice = [\"MORDRED\", \"RDKIT\", \"MORGAN_FP\"]\n",
    "\n",
    "parameters = [ \n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time_h\",\n",
    "    values = lookup['Time_h'].unique()\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values = lookup['pH'].unique()\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhib_Concentrat_M\",\n",
    "    values=lookup['Inhib_Concentrat_M'].unique(), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt_Concentrat_M\",\n",
    "    values=lookup['Salt_Concentrat_M'].unique(),\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data=smiles_dict,\n",
    "    encoding=\"MORGAN_FP\", # Which is better?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 11.9 GiB for an array with shape (384, 4151250) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m searchspace \u001b[38;5;241m=\u001b[39m \u001b[43mSearchSpace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/baybe/searchspace/core.py:137\u001b[0m, in \u001b[0;36mSearchSpace.from_product\u001b[0;34m(cls, parameters, constraints, empty_encoding)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     constraints \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 137\u001b[0m discrete: SubspaceDiscrete \u001b[38;5;241m=\u001b[39m \u001b[43mSubspaceDiscrete\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_product\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDiscreteParameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDiscreteConstraint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_discrete\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mempty_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m continuous: SubspaceContinuous \u001b[38;5;241m=\u001b[39m SubspaceContinuous(\n\u001b[1;32m    145\u001b[0m     parameters\u001b[38;5;241m=\u001b[39m[p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, ContinuousParameter)],\n\u001b[1;32m    146\u001b[0m     constraints_lin_eq\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     ],\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SearchSpace(discrete\u001b[38;5;241m=\u001b[39mdiscrete, continuous\u001b[38;5;241m=\u001b[39mcontinuous)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/baybe/searchspace/discrete.py:216\u001b[0m, in \u001b[0;36mSubspaceDiscrete.from_product\u001b[0;34m(cls, parameters, constraints, empty_encoding)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Remove entries that violate parameter constraints\u001b[39;00m\n\u001b[1;32m    214\u001b[0m _apply_constraint_filter(exp_rep, constraints)\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSubspaceDiscrete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mempty_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mempty_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<attrs generated init baybe.searchspace.discrete.SubspaceDiscrete>:17\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, parameters, exp_rep, metadata, empty_encoding, constraints, comp_rep)\u001b[0m\n\u001b[1;32m     15\u001b[0m     _setattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomp_rep\u001b[39m\u001b[38;5;124m'\u001b[39m, comp_rep)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     _setattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomp_rep\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43m__attr_factory_comp_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _config\u001b[38;5;241m.\u001b[39m_run_validators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     __attr_validator_parameters(\u001b[38;5;28mself\u001b[39m, __attr_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/baybe/searchspace/discrete.py:159\u001b[0m, in \u001b[0;36mSubspaceDiscrete._default_comp_rep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create the default computational representation.\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Create a dataframe containing the computational parameter representation\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m comp_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_rep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Ignore all columns that do not carry any covariate information\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# TODO[12758]: This logic needs to be refined, i.e. when should we drop columns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m#   and when not (can have undesired/unexpected side-effects). Should this be\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m#   configurable at the parameter level? A hotfix was made to exclude task\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m#   parameters, but this needs to be revisited as well.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m comp_rep \u001b[38;5;241m=\u001b[39m df_drop_single_value_columns(\n\u001b[1;32m    167\u001b[0m     comp_rep, [p\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, TaskParameter)]\n\u001b[1;32m    168\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/baybe/searchspace/discrete.py:569\u001b[0m, in \u001b[0;36mSubspaceDiscrete.transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    567\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters:\n\u001b[0;32m--> 569\u001b[0m     comp_df \u001b[38;5;241m=\u001b[39m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_rep_exp2comp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(comp_df)\n\u001b[1;32m    571\u001b[0m comp_rep \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m dfs \u001b[38;5;28;01melse\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/baybe/parameters/base.py:94\u001b[0m, in \u001b[0;36mDiscreteParameter.transform_rep_exp2comp\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform data from experimental to computational representation.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    The transformed version of the data.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# replace each label with the corresponding encoding\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomp_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_frame()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/reshape/merge.py:863\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    858\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(\n\u001b[1;32m    861\u001b[0m     right_indexer, \u001b[38;5;28mlen\u001b[39m(right)\n\u001b[1;32m    862\u001b[0m ):\n\u001b[0;32m--> 863\u001b[0m     rmgr \u001b[38;5;241m=\u001b[39m \u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(rmgr, axes\u001b[38;5;241m=\u001b[39mrmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    873\u001b[0m right\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[1;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    693\u001b[0m             ),\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 11.9 GiB for an array with shape (384, 4151250) and data type int64"
     ]
    }
   ],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = Campaign(searchspace=searchspace, objective=objective)\n",
    "campaign_rand = Campaign(\n",
    "    searchspace=searchspace,\n",
    "    recommender=TwoPhaseMetaRecommender(recommender=RandomRecommender()),\n",
    "    objective=objective,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\"Test_Scenario\": campaign, \"Random\": campaign_rand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_scenarios(\n",
    "    scenarios,\n",
    "    lookup,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_doe_iterations=N_DOE_ITERATIONS,\n",
    "    n_mc_iterations=N_MC_ITERATIONS,\n",
    "    impute_mode=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" max_yield = lookup[\"yield\"].max()\n",
    "sns.lineplot(\n",
    "    data=results, x=\"Num_Experiments\", y=\"yield_CumBest\", hue=\"Scenario\", marker=\"x\"\n",
    ")\n",
    "plt.plot([3, 3 * N_DOE_ITERATIONS], [max_yield, max_yield], \"--r\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.gcf().set_size_inches(20, 8)\n",
    "plt.savefig(\"./run_impute_mode.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will focus on exploring the capabilities of Bayesian optimization, specifically employing BayBE, in the discovery of novel corrosion inhibitors for materials design. Initially, we will work with a randomly chosen subset from a comprehensive database of electrochemical responses of small organic molecules. Our goal is to assess how Bayesian optimization can speed up the screening process across the design space to identify promising compounds. We will compare different strategies for incorporating alloy information, while optimizing the experimental parameters with respect to the inhibitive performance of the screened compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initizalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries and data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_AA2024 = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "# df_AA1000 = pd.read_excel('data/filtered_AA1000.xlsx')\n",
    "# df_Al = pd.read_excel('data/filtered_Al.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all unique SMILES values into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SMILES = df_AA2024.SMILES.unique()\n",
    "\n",
    "def list_to_dict(input_list):\n",
    "    return {item: item for item in input_list}\n",
    "\n",
    "smiles_dict =list_to_dict(unique_SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.parameters import SubstanceParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "encoding_choice = [\"MORDRED\", \"RDKIT\", \"MORGAN_FP\"]\n",
    "\n",
    "parameters = [ \n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time_h\",\n",
    "    values = df_AA2024['Time_h'].unique()\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values = df_AA2024['pH'].unique()\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhib_Concentrat_M\",\n",
    "    values=df_AA2024['Inhib_Concentrat_M'].unique(), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt_Concentrat_M\",\n",
    "    values=df_AA2024['Salt_Concentrat_M'].unique(),\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data=smiles_dict,\n",
    "    encoding=\"MORGAN_FP\", # Which is better?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculations will typically result in 500 to 1500 numbers per molecule. **To avoid detrimental effects on the surrogate model fit, we reduce the number of descriptors via decorrelation before using them.** For instance, the decorrelate option in the example above specifies that only descriptors with a correlation lower than 0.7 to any other descriptor will be kept. This usually reduces the number of descriptors to 10-50, depending on the specific items in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The encoding concept introduced above is generalized by the CustomParameter. Here, the user is expected to provide their own descriptors for the encoding.\n",
    "\n",
    "Take, for instance, a parameter that corresponds to the choice of a polymer. Polymers are not well represented by the small molecule descriptors utilized in the SubstanceParameter. \n",
    "Still, one could provide experimental measurements or common metrics used to classify polymers:\n",
    "from baybe.parameters import CustomDiscreteParameter\n",
    "\n",
    "# Create or import new dataframe containing custom descriptors\n",
    "\n",
    "descriptors = pd.DataFrame(\n",
    "    {\n",
    "        \"Glass_Transition_TempC\": [20, -71, -39],\n",
    "        \"Weight_kDalton\": [120, 32, 241],\n",
    "    },\n",
    "    index=[\"Polymer A\", \"Polymer B\", \"Polymer C\"],  # put labels in the index\n",
    ")\n",
    "\n",
    "CustomDiscreteParameter(\n",
    "    name=\"Polymer\",\n",
    "    data=descriptors,\n",
    "    decorrelate=True,  # optional, uses default correlation threshold = 0.7?\n",
    ")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(searchspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.recommenders import RandomRecommender, SequentialGreedyRecommender\n",
    "from baybe.surrogates import GaussianProcessSurrogate\n",
    "\n",
    "available_surr_models = [\n",
    "    \"GaussianProcessSurrogate\", \n",
    "    \"BayesianLinearSurrogate\",\n",
    "    \"MeanPredictionSurrogate\",\n",
    "    \"NGBoostSurrogate\",\n",
    "    \"RandomForestSurrogate\"\n",
    "]\n",
    "\n",
    "available_acq_functions = [\n",
    "    \"qPI\",  # q-Probability Of Improvement\n",
    "    \"qEI\",  # q-Expected Improvement\n",
    "    \"qUCB\", # q-upper confidence bound with beta of 1.0\n",
    "]\n",
    "\n",
    "# Defaults anyway\n",
    "SURROGATE_MODEL = GaussianProcessSurrogate()\n",
    "ACQ_FUNCTION = \"qEI\" # q-Expected Improvement, only q-fuctions are available for batch_size > 1\n",
    "\n",
    "seq_greedy_recommender = SequentialGreedyRecommender(\n",
    "        surrogate_model=SURROGATE_MODEL,\n",
    "        acquisition_function_cls=ACQ_FUNCTION,\n",
    "        hybrid_sampler=\"Farthest\", # find more details in the documentation\n",
    "        sampling_percentage=0.3, # should be relatively low\n",
    "        allow_repeated_recommendations=False,\n",
    "        allow_recommending_already_measured=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.strategies import TwoPhaseStrategy\n",
    "from baybe import Campaign\n",
    "\n",
    "strategy = TwoPhaseStrategy(\n",
    "    initial_recommender = RandomRecommender(),  # Initial recommender\n",
    "    # Doesn't matter since I already have training data, BUT CAN BE USED FOR BENCHMARKING\n",
    "    recommender = seq_greedy_recommender,  # Bayesian model-based optimization\n",
    "    switch_after=1  # Switch to the model-based recommender after 1 batches = immediately\n",
    ")\n",
    "\n",
    "campaign = Campaign(searchspace, objective, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rec = campaign.recommend(batch_size=1) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and input efficiency value from Excel table, for specific SMILES component first, \n",
    "# then for the closest values of the rest of the parameters\n",
    "\n",
    "new_rec[\"Efficiency\"] = [0.1]\n",
    "campaign.add_measurements(new_rec)\n",
    "\n",
    "print(\"\\n\\nRecommended experiments with measured values: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_rec = campaign.recommend(batch_size=1) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([new_rec, new_new_rec]) # etc.\n",
    "print(\"\\n\\nAll experiments with measured values: \")\n",
    "print(results.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Transfer_Learning/basic_transfer_learning.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/userguide/transfer_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/userguide/simulation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Backtesting/impute_mode.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
