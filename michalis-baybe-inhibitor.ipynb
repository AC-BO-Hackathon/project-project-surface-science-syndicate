{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will focus on exploring the capabilities of Bayesian optimization, specifically employing BayBE, in the discovery of novel corrosion inhibitors for materials design. Initially, we will work with a randomly chosen subset from a comprehensive database of electrochemical responses of small organic molecules. Our goal is to assess how Bayesian optimization can speed up the screening process across the design space to identify promising compounds. We will compare different strategies for incorporating alloy information, while optimizing the experimental parameters with respect to the inhibitive performance of the screened compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initizalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries and data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_AA2024 = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "# df_AA1000 = pd.read_excel('data/filtered_AA1000.xlsx')\n",
    "# df_Al = pd.read_excel('data/filtered_Al.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all unique SMILES values into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SMILES = df_AA2024.SMILES.unique()\n",
    "\n",
    "def list_to_dict(input_list):\n",
    "    return {item: item for item in input_list}\n",
    "\n",
    "smiles_dict =list_to_dict(unique_SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "parameters = [\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time (h)\",\n",
    "    values=np.arange(1, 25, 1)\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values=np.arange(-1, 15.1, 0.1)\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhibitor Concentration (M)\",\n",
    "    values=np.arange(0, 0.1, 0.01), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt Concentration (M)\",\n",
    "    values=np.arange(0, 2.01, 0.01),\n",
    "    # tolerance = 0.004\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import SubstanceParameter\n",
    "\n",
    "encoding_choice = [\"MORDRED\", \"RDKIT\", \"MORGAN_FP\"]\n",
    "\n",
    "SubstanceParameter(\n",
    "    name=\"Inhibitor\",\n",
    "    data=smiles_dict,\n",
    "    encoding=\"MORDRED\",  # Can be also RDKIT or MORGAN_FP - WHICH IS BETTER?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculations will typically result in 500 to 1500 numbers per molecule. **To avoid detrimental effects on the surrogate model fit, we reduce the number of descriptors via decorrelation before using them.** For instance, the decorrelate option in the example above specifies that only descriptors with a correlation lower than 0.7 to any other descriptor will be kept. This usually reduces the number of descriptors to 10-50, depending on the specific items in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The encoding concept introduced above is generalized by the CustomParameter. Here, the user is expected to provide their own descriptors for the encoding.\n",
    "\n",
    "Take, for instance, a parameter that corresponds to the choice of a polymer. Polymers are not well represented by the small molecule descriptors utilized in the SubstanceParameter. \n",
    "Still, one could provide experimental measurements or common metrics used to classify polymers:\n",
    "from baybe.parameters import CustomDiscreteParameter\n",
    "\n",
    "# Create or import new dataframe containing custom descriptors\n",
    "\n",
    "descriptors = pd.DataFrame(\n",
    "    {\n",
    "        \"Glass_Transition_TempC\": [20, -71, -39],\n",
    "        \"Weight_kDalton\": [120, 32, 241],\n",
    "    },\n",
    "    index=[\"Polymer A\", \"Polymer B\", \"Polymer C\"],  # put labels in the index\n",
    ")\n",
    "\n",
    "CustomDiscreteParameter(\n",
    "    name=\"Polymer\",\n",
    "    data=descriptors,\n",
    "    decorrelate=True,  # optional, uses default correlation threshold = 0.7?\n",
    ")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.recommenders import RandomRecommender, SequentialGreedyRecommender\n",
    "from baybe.surrogates import GaussianProcessSurrogate\n",
    "\n",
    "available_surr_models = [\n",
    "    \"GaussianProcessSurrogate\", \n",
    "    \"BayesianLinearSurrogate\",\n",
    "    \"MeanPredictionSurrogate\",\n",
    "    \"NGBoostSurrogate\",\n",
    "    \"RandomForestSurrogate\"\n",
    "]\n",
    "\n",
    "available_acq_functions = [\n",
    "    \"qPI\",  # q-Probability Of Improvement\n",
    "    \"qEI\",  # q-Expected Improvement\n",
    "    \"qUCB\", # q-upper confidence bound with beta of 1.0\n",
    "]\n",
    "\n",
    "# Defaults anyway\n",
    "SURROGATE_MODEL = GaussianProcessSurrogate()\n",
    "ACQ_FUNCTION = \"qEI\" # q-Expected Improvement, only q-fuctions are available for batch_size > 1\n",
    "\n",
    "seq_greedy_recommender = SequentialGreedyRecommender(\n",
    "        surrogate_model=SURROGATE_MODEL,\n",
    "        acquisition_function_cls=ACQ_FUNCTION,\n",
    "        hybrid_sampler=\"Farthest\", # find more details in the documentation\n",
    "        sampling_percentage=0.3, # should be relatively low\n",
    "        allow_repeated_recommendations=False,\n",
    "        allow_recommending_already_measured=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.strategies import TwoPhaseStrategy\n",
    "from baybe import Campaign\n",
    "\n",
    "strategy = TwoPhaseStrategy(\n",
    "    initial_recommender = RandomRecommender(),  # Initial recommender\n",
    "    # Doesn't matter since I already have training data, BUT CAN BE USED FOR BENCHMARKING\n",
    "    recommender = seq_greedy_recommender,  # Bayesian model-based optimization\n",
    "    switch_after=1  # Switch to the model-based recommender after 1 batches = immediately\n",
    ")\n",
    "\n",
    "campaign = Campaign(searchspace, objective, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rec = campaign.recommend(batch_size=3) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and input efficiency value from Excel table, for specific SMILES component first, \n",
    "# then for the closest values of the rest of the parameters\n",
    "\n",
    "new_rec[\"efficiency\"] = [0.1, 0.2, 0.3]\n",
    "print(\"\\n\\nRecommended experiments with measured values: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wtf, why is recommending the same values as before here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_rec = campaign.recommend(batch_size=3) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([new_rec, new_new_rec]) # etc.\n",
    "print(\"\\n\\nAll experiments with measured values: \")\n",
    "print(results.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Transfer_Learning/basic_transfer_learning.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/userguide/transfer_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Backtesting/full_initial_data.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/examples/Backtesting/full_lookup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/userguide/simulation.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
