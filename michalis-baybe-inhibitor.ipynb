{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/baybe/telemetry.py:222: UserWarning: WARNING: BayBE Telemetry endpoint https://public.telemetry.baybe.p.uptimize.merckgroup.com:4317 cannot be reached. Disabling telemetry. The exception encountered was: ConnectionError, HTTPConnectionPool(host='verkehrsnachrichten.merck.de', port=80): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7f3bb09b7fa0>: Failed to resolve 'verkehrsnachrichten.merck.de' ([Errno -2] Name or service not known)\"))\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from baybe import Campaign\n",
    "from baybe.objective import Objective\n",
    "from baybe.parameters import NumericalDiscreteParameter, SubstanceParameter\n",
    "from baybe.recommenders import RandomRecommender, TwoPhaseMetaRecommender\n",
    "from baybe.searchspace import SearchSpace\n",
    "from baybe.simulation import simulate_scenarios\n",
    "from baybe.targets import NumericalTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOKE_TEST = \"SMOKE_TEST\" in os.environ\n",
    "N_MC_ITERATIONS = 2 if SMOKE_TEST else 5\n",
    "N_DOE_ITERATIONS = 2 if SMOKE_TEST else 5\n",
    "BATCH_SIZE = 1 if SMOKE_TEST else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "\n",
    "# So that the searchspace from dataframe works, and matches the columns\n",
    "lookup = lookup.drop(columns='Efficiency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      SMILES  Time_h    pH  \\\n",
      "0               COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0   4.0   \n",
      "1               COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0  10.0   \n",
      "2              Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0   4.0   \n",
      "3              Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0  10.0   \n",
      "4    Clc1ccc(cc1)CC[C@](C(C)(C)C)(Cn1cncn1)O    24.0   4.0   \n",
      "..                                       ...     ...   ...   \n",
      "606                     S=c1sc2c([nH]1)cccc2    24.0   7.0   \n",
      "607    C(C(=O)[O-])C(CC(=O)[O-])(C(=O)[O-])O    24.0   7.0   \n",
      "608    C(C(=O)[O-])C(CC(=O)[O-])(C(=O)[O-])O    24.0   7.0   \n",
      "609                     C(=O)(C(=O)[O-])[O-]    24.0   7.0   \n",
      "610                     C(=O)(C(=O)[O-])[O-]    24.0   7.0   \n",
      "\n",
      "     Inhib_Concentrat_M  Salt_Concentrat_M  \n",
      "0                0.0010               0.10  \n",
      "1                0.0010               0.10  \n",
      "2                0.0010               0.10  \n",
      "3                0.0010               0.10  \n",
      "4                0.0010               0.10  \n",
      "..                  ...                ...  \n",
      "606              0.0005               0.05  \n",
      "607              0.0005               0.05  \n",
      "608              0.0005               0.05  \n",
      "609              0.0005               0.05  \n",
      "610              0.0005               0.05  \n",
      "\n",
      "[611 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SMILES = lookup.SMILES.unique()\n",
    "\n",
    "def list_to_dict(input_list):\n",
    "    return {item: item for item in input_list}\n",
    "\n",
    "smiles_dict =list_to_dict(unique_SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.parameters import SubstanceParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "encoding_choice = [\"MORDRED\", \"RDKIT\", \"MORGAN_FP\"]\n",
    "\n",
    "parameters = [ \n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time_h\",\n",
    "    values = lookup['Time_h'].unique()\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values = lookup['pH'].unique()\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhib_Concentrat_M\",\n",
    "    values=lookup['Inhib_Concentrat_M'].unique(), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt_Concentrat_M\",\n",
    "    values=lookup['Salt_Concentrat_M'].unique(),\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data=smiles_dict,\n",
    "    encoding=\"MORGAN_FP\", # Which is better?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SearchSpace.from_dataframe() missing 1 required positional argument: 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m searchspace \u001b[38;5;241m=\u001b[39m \u001b[43mSearchSpace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSMILES\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTime_h\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInhib_Concentrat_M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalt_Concentrat_M\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SearchSpace.from_dataframe() missing 1 required positional argument: 'df'"
     ]
    }
   ],
   "source": [
    "# Effort\n",
    "searchspace = SearchSpace.from_dataframe(parameters = lookup[[\"SMILES\", \"Time_h\", \"pH\", \"Inhib_Concentrat_M\", \"Salt_Concentrat_M\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = Campaign(searchspace=searchspace, objective=objective)\n",
    "campaign_rand = Campaign(\n",
    "    searchspace=searchspace,\n",
    "    recommender=TwoPhaseMetaRecommender(recommender=RandomRecommender()),\n",
    "    objective=objective,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\"Test_Scenario\": campaign, \"Random\": campaign_rand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = simulate_scenarios(\n",
    "    scenarios,\n",
    "    lookup,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    n_doe_iterations=N_DOE_ITERATIONS,\n",
    "    n_mc_iterations=N_MC_ITERATIONS,\n",
    "    impute_mode=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" max_yield = lookup[\"yield\"].max()\n",
    "sns.lineplot(\n",
    "    data=results, x=\"Num_Experiments\", y=\"yield_CumBest\", hue=\"Scenario\", marker=\"x\"\n",
    ")\n",
    "plt.plot([3, 3 * N_DOE_ITERATIONS], [max_yield, max_yield], \"--r\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.gcf().set_size_inches(20, 8)\n",
    "plt.savefig(\"./run_impute_mode.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will focus on exploring the capabilities of Bayesian optimization, specifically employing BayBE, in the discovery of novel corrosion inhibitors for materials design. Initially, we will work with a randomly chosen subset from a comprehensive database of electrochemical responses of small organic molecules. Our goal is to assess how Bayesian optimization can speed up the screening process across the design space to identify promising compounds. We will compare different strategies for incorporating alloy information, while optimizing the experimental parameters with respect to the inhibitive performance of the screened compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initizalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading libraries and data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_AA2024 = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "# df_AA1000 = pd.read_excel('data/filtered_AA1000.xlsx')\n",
    "# df_Al = pd.read_excel('data/filtered_Al.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_AA2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all unique SMILES values into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_SMILES = df_AA2024.SMILES.unique()\n",
    "\n",
    "def list_to_dict(input_list):\n",
    "    return {item: item for item in input_list}\n",
    "\n",
    "smiles_dict =list_to_dict(unique_SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.parameters import SubstanceParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "encoding_choice = [\"MORDRED\", \"RDKIT\", \"MORGAN_FP\"]\n",
    "\n",
    "parameters = [ \n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time_h\",\n",
    "    values = df_AA2024['Time_h'].unique()\n",
    "    # tolerance = 0.004, assume certain experimental noise for each parameter measurement?\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values = df_AA2024['pH'].unique()\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalDiscreteParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhib_Concentrat_M\",\n",
    "    values=df_AA2024['Inhib_Concentrat_M'].unique(), # Remove data outliers like 0.1?\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt_Concentrat_M\",\n",
    "    values=df_AA2024['Salt_Concentrat_M'].unique(),\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data=smiles_dict,\n",
    "    encoding=\"MORGAN_FP\", # Which is better?\n",
    "    decorrelate=0.7,  # Change threshold to avoid overfitting?\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculations will typically result in 500 to 1500 numbers per molecule. **To avoid detrimental effects on the surrogate model fit, we reduce the number of descriptors via decorrelation before using them.** For instance, the decorrelate option in the example above specifies that only descriptors with a correlation lower than 0.7 to any other descriptor will be kept. This usually reduces the number of descriptors to 10-50, depending on the specific items in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The encoding concept introduced above is generalized by the CustomParameter. Here, the user is expected to provide their own descriptors for the encoding.\n",
    "\n",
    "Take, for instance, a parameter that corresponds to the choice of a polymer. Polymers are not well represented by the small molecule descriptors utilized in the SubstanceParameter. \n",
    "Still, one could provide experimental measurements or common metrics used to classify polymers:\n",
    "from baybe.parameters import CustomDiscreteParameter\n",
    "\n",
    "# Create or import new dataframe containing custom descriptors\n",
    "\n",
    "descriptors = pd.DataFrame(\n",
    "    {\n",
    "        \"Glass_Transition_TempC\": [20, -71, -39],\n",
    "        \"Weight_kDalton\": [120, 32, 241],\n",
    "    },\n",
    "    index=[\"Polymer A\", \"Polymer B\", \"Polymer C\"],  # put labels in the index\n",
    ")\n",
    "\n",
    "CustomDiscreteParameter(\n",
    "    name=\"Polymer\",\n",
    "    data=descriptors,\n",
    "    decorrelate=True,  # optional, uses default correlation threshold = 0.7?\n",
    ")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_dataframe(df_AA2024[[\"SMILES\", \"Time_h\", \"pH\", \"Inhib_Concentrat_M\", \"Salt_Concentrat_M\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(searchspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.recommenders import RandomRecommender, SequentialGreedyRecommender\n",
    "from baybe.surrogates import GaussianProcessSurrogate\n",
    "\n",
    "available_surr_models = [\n",
    "    \"GaussianProcessSurrogate\", \n",
    "    \"BayesianLinearSurrogate\",\n",
    "    \"MeanPredictionSurrogate\",\n",
    "    \"NGBoostSurrogate\",\n",
    "    \"RandomForestSurrogate\"\n",
    "]\n",
    "\n",
    "available_acq_functions = [\n",
    "    \"qPI\",  # q-Probability Of Improvement\n",
    "    \"qEI\",  # q-Expected Improvement\n",
    "    \"qUCB\", # q-upper confidence bound with beta of 1.0\n",
    "]\n",
    "\n",
    "# Defaults anyway\n",
    "SURROGATE_MODEL = GaussianProcessSurrogate()\n",
    "ACQ_FUNCTION = \"qEI\" # q-Expected Improvement, only q-fuctions are available for batch_size > 1\n",
    "\n",
    "seq_greedy_recommender = SequentialGreedyRecommender(\n",
    "        surrogate_model=SURROGATE_MODEL,\n",
    "        acquisition_function_cls=ACQ_FUNCTION,\n",
    "        hybrid_sampler=\"Farthest\", # find more details in the documentation\n",
    "        sampling_percentage=0.3, # should be relatively low\n",
    "        allow_repeated_recommendations=False,\n",
    "        allow_recommending_already_measured=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.strategies import TwoPhaseStrategy\n",
    "from baybe import Campaign\n",
    "\n",
    "strategy = TwoPhaseStrategy(\n",
    "    initial_recommender = RandomRecommender(),  # Initial recommender\n",
    "    # Doesn't matter since I already have training data, BUT CAN BE USED FOR BENCHMARKING\n",
    "    recommender = seq_greedy_recommender,  # Bayesian model-based optimization\n",
    "    switch_after=1  # Switch to the model-based recommender after 1 batches = immediately\n",
    ")\n",
    "\n",
    "campaign = Campaign(searchspace, objective, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rec = campaign.recommend(batch_size=1) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and input efficiency value from Excel table, for specific SMILES component first, \n",
    "# then for the closest values of the rest of the parameters\n",
    "\n",
    "new_rec[\"Efficiency\"] = [0.1]\n",
    "campaign.add_measurements(new_rec)\n",
    "\n",
    "print(\"\\n\\nRecommended experiments with measured values: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_rec = campaign.recommend(batch_size=1) # TEST with different batch sizes for optimal performance\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(campaign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([new_rec, new_new_rec]) # etc.\n",
    "print(\"\\n\\nAll experiments with measured values: \")\n",
    "print(results.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Transfer_Learning/basic_transfer_learning.html\n",
    "\n",
    "https://emdgroup.github.io/baybe/userguide/transfer_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/userguide/simulation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://emdgroup.github.io/baybe/examples/Backtesting/impute_mode.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
