{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Time_h          pH  Inhib_Concentrat_M   Efficiency\n",
      "count  611.000000  611.000000          611.000000   611.000000\n",
      "mean   135.801964    6.342062            0.006808    26.736841\n",
      "std    201.683867    2.529080            0.014059   288.788317\n",
      "min      0.500000    0.000000            0.000010 -4834.000000\n",
      "25%     24.000000    4.000000            0.000500    30.000000\n",
      "50%     24.000000    7.000000            0.001000    58.000000\n",
      "75%    144.000000    7.000000            0.003000    87.950000\n",
      "max    672.000000   10.000000            0.100000   100.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_AA2024 = pd.read_excel('data/filtered_AA2024.xlsx')\n",
    "print(df_AA2024.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    SMILES  Time_h    pH  Inhib_Concentrat_M  \\\n",
      "0             COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0   4.0               0.001   \n",
      "1             COCCOC(=O)OCSc1nc2c(s1)cccc2    24.0  10.0               0.001   \n",
      "2            Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0   4.0               0.001   \n",
      "3            Cc1ccc(c(c1)n1nc2c(n1)cccc2)O    24.0  10.0               0.001   \n",
      "4  Clc1ccc(cc1)CC[C@](C(C)(C)C)(Cn1cncn1)O    24.0   4.0               0.001   \n",
      "\n",
      "   Efficiency  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2        30.0  \n",
      "3        30.0  \n",
      "4        30.0  \n"
     ]
    }
   ],
   "source": [
    "print(df_AA2024.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set targets/objectives = efficiency for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.targets import NumericalTarget\n",
    "from baybe.objective import Objective\n",
    "\n",
    "target = NumericalTarget(\n",
    "    name=\"Efficiency\",\n",
    "    mode=\"MAX\",\n",
    ")\n",
    "objective = Objective(mode=\"SINGLE\", targets=[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.parameters import NumericalDiscreteParameter, NumericalContinuousParameter\n",
    "from baybe.searchspace import SearchSpace\n",
    "\n",
    "parameters = [\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Time (h)\",\n",
    "    values=np.arange(1, 25, 1)\n",
    "    # tolerance = 0.004\n",
    "),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"pH\",\n",
    "    values=np.arange(-1, 15.1, 0.1)\n",
    "    # tolerance = 0.004\n",
    "    ),  \n",
    "NumericalContinuousParameter( # Set this as continuous, the values seem quite small?\n",
    "    name=\"Inhibitor Concentration (M)\",\n",
    "    bounds=(0, 0.02)\n",
    "    # tolerance = 0.004\n",
    "    ),\n",
    "NumericalDiscreteParameter(\n",
    "    name=\"Salt Concentration (M)\",\n",
    "    values=np.arange(0, 2.01, 0.01),\n",
    "    # tolerance = 0.004\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Substance parameter**\n",
    "\n",
    "Instead of values, this parameter accepts data in form of a dictionary. The items correspond to pairs of labels and SMILES. SMILES are string-based representations of molecular structures. Based on these, BayBE can assign each label a set of molecular descriptors as encoding.\n",
    "\n",
    "For instance, a parameter corresponding to a choice of solvents can be initialized with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubstanceParameter(name='Solvent', data={'Water': 'O', '1-Octanol': 'CCCCCCCCO', 'Toluene': 'CC1=CC=CC=C1'}, decorrelate=0.7, encoding=<SubstanceEncoding.MORDRED: 'MORDRED'>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from baybe.parameters import SubstanceParameter\n",
    "\n",
    "SubstanceParameter(\n",
    "    name=\"SMILES\",\n",
    "    data={\n",
    "        # df_AA2024 SMILES column\n",
    "        \"Water\": \"O\",\n",
    "        \"1-Octanol\": \"CCCCCCCCO\",\n",
    "        \"Toluene\": \"CC1=CC=CC=C1\",\n",
    "    },\n",
    "    encoding=\"MORDRED\",  # optional\n",
    "    decorrelate=0.7,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The encoding option defines what kind of descriptors are calculated:\n",
    "\n",
    "MORDRED: 2D descriptors from the Mordred package. Since the original package is now unmaintained, baybe requires the community replacement mordredcommunity\n",
    "\n",
    "RDKIT: 2D descriptors from the RDKit package\n",
    "\n",
    "MORGAN_FP: Morgan fingerprints calculated with RDKit (1024 bits, radius 4)\n",
    "\n",
    "These calculations will typically result in 500 to 1500 numbers per molecule. **To avoid detrimental effects on the surrogate model fit, we reduce the number of descriptors via decorrelation before using them.** For instance, the decorrelate option in the example above specifies that only descriptors with a correlation lower than 0.7 to any other descriptor will be kept. This usually reduces the number of descriptors to 10-50, depending on the specific items in data.\n",
    "\n",
    "**WARNING:**\n",
    "The descriptors calculated for a SubstanceParameter were developed to describe small molecules and are not suitable for other substances. If you deal with large molecules like polymers or arbitrary substance mixtures, we recommend to provide your own descriptors via the CustomParameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding concept introduced above is generalized by the CustomParameter. Here, the user is expected to provide their own descriptors for the encoding.\n",
    "\n",
    "Take, for instance, a parameter that corresponds to the choice of a polymer. Polymers are not well represented by the small molecule descriptors utilized in the SubstanceParameter. Still, one could provide experimental measurements or common metrics used to classify polymers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDiscreteParameter(name='Polymer', data=           Glass_Transition_TempC  Weight_kDalton\n",
       "Polymer A                      20             120\n",
       "Polymer B                     -71              32\n",
       "Polymer C                     -39             241, decorrelate=True, encoding=<CustomEncoding.CUSTOM: 'CUSTOM'>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from baybe.parameters import CustomDiscreteParameter\n",
    "\n",
    "# Create or import new dataframe containing custom descriptors\n",
    "\n",
    "descriptors = pd.DataFrame(\n",
    "    {\n",
    "        \"Glass_Transition_TempC\": [20, -71, -39],\n",
    "        \"Weight_kDalton\": [120, 32, 241],\n",
    "    },\n",
    "    index=[\"Polymer A\", \"Polymer B\", \"Polymer C\"],  # put labels in the index\n",
    ")\n",
    "\n",
    "CustomDiscreteParameter(\n",
    "    name=\"Polymer\",\n",
    "    data=descriptors,\n",
    "    decorrelate=True,  # optional, uses default correlation threshold = 0.7?\n",
    ")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchspace = SearchSpace.from_product(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **SequentialGreedyRecommender** is a powerful recommender that leverages BoTorch optimization functions to perform sequential Greedy optimization. It can be applied for discrete, continuous and hybrid sarch spaces. It is an implementation of the BoTorch optimization functions for discrete, continuous and mixed spaces. **It is important to note that this recommender performs a brute-force search when applied in hybrid search spaces, as it optimizes the continuous part of the space while exhaustively searching choices in the discrete subspace.** You can customize this behavior to only sample a certain percentage of the discrete subspace via the sample_percentage attribute and to choose different sampling strategies via the hybrid_sampler attribute. \n",
    "\n",
    "e.g.\n",
    "strategy = TwoPhaseStrategy(recommender=SequentialGreedyRecommender(hybrid_sampler=\"Farthest\", sampling_percentage=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For implementing fully customized surrogate models e.g. from sklearn or PyTorch, see:\n",
    "https://emdgroup.github.io/baybe/examples/Custom_Surrogates/Custom_Surrogates.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baybe.recommenders import RandomRecommender, SequentialGreedyRecommender\n",
    "from baybe.surrogates import GaussianProcessSurrogate\n",
    "\n",
    "available_surr_models = [\n",
    "    \"GaussianProcessSurrogate\", \n",
    "    \"BayesianLinearSurrogate\",\n",
    "    \"MeanPredictionSurrogate\",\n",
    "    \"NGBoostSurrogate\",\n",
    "    \"RandomForestSurrogate\"\n",
    "]\n",
    "\n",
    "available_acq_functions = [\n",
    "    \"qPI\",  # q-Probability Of Improvement\n",
    "    \"qEI\",  # q-Expected Improvement\n",
    "    \"qUCB\", # q-upper confidence bound with beta of 1.0\n",
    "]\n",
    "\n",
    "# Defaults anyway\n",
    "SURROGATE_MODEL = GaussianProcessSurrogate()\n",
    "ACQ_FUNCTION = \"qEI\" # q-Expected Improvement, only q-fuctions are available for batch_size > 1\n",
    "\n",
    "seq_greedy_recommender = SequentialGreedyRecommender(\n",
    "        surrogate_model=SURROGATE_MODEL,\n",
    "        acquisition_function_cls=ACQ_FUNCTION,\n",
    "        hybrid_sampler=\"Farthest\", # find more details in the documentation\n",
    "        sampling_percentage=0.3, # should be relatively low\n",
    "        allow_repeated_recommendations=False,\n",
    "        allow_recommending_already_measured=False,\n",
    "    )\n",
    "\n",
    "hybrid_recommender = SequentialGreedyRecommender(\n",
    "    allow_repeated_recommendations=False,\n",
    "    allow_recommending_already_measured=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campaign Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/baybe/strategies/deprecation.py:26: DeprecationWarning: 'TwoPhaseStrategy' is deprecated and will be removed in a future version. Please use 'recommenders.TwoPhaseMetaRecommender' class instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from baybe.strategies import TwoPhaseStrategy\n",
    "from baybe import Campaign\n",
    "\n",
    "strategy = TwoPhaseStrategy(\n",
    "    initial_recommender = RandomRecommender(),  # Initial recommender, if no training data is available\n",
    "    # Other initial recommenders don't seem to work for my hybrid search space/set of parameters\n",
    "    # Doesn't matter since I already have training data\n",
    "    recommender = seq_greedy_recommender,  # Bayesian model-based optimization\n",
    "    # recommender = hybrid_recommender,\n",
    "    switch_after=1  # Switch to the model-based recommender after 1 batch or iteration (so the initial training data)\n",
    ")\n",
    "\n",
    "campaign = Campaign(searchspace, objective, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommended experiments: \n",
      "|        |   Time (h) |   pH |   Salt Concentration (M) |   Inhibitor Concentration (M) |\n",
      "|-------:|-----------:|-----:|-------------------------:|------------------------------:|\n",
      "| 492324 |         16 |  2.4 |                     0.75 |                    0.0150329  |\n",
      "| 341299 |         11 |  7.8 |                     0.01 |                    0.00234041 |\n",
      "| 470340 |         15 |  7.6 |                     0    |                    0.00838565 |\n"
     ]
    }
   ],
   "source": [
    "new_rec = campaign.recommend(batch_size=3)\n",
    "print(\"\\n\\nRecommended experiments: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recommended experiments with measured values: \n",
      "|        |   Time (h) |   pH |   Salt Concentration (M) |   Inhibitor Concentration (M) |   efficiency |\n",
      "|-------:|-----------:|-----:|-------------------------:|------------------------------:|-------------:|\n",
      "| 492324 |         16 |  2.4 |                     0.75 |                    0.0150329  |          0.1 |\n",
      "| 341299 |         11 |  7.8 |                     0.01 |                    0.00234041 |          0.2 |\n",
      "| 470340 |         15 |  7.6 |                     0    |                    0.00838565 |          0.3 |\n"
     ]
    }
   ],
   "source": [
    "new_rec[\"efficiency\"] = [0.1,0.2,0.3]\n",
    "print(\"\\n\\nRecommended experiments with measured values: \")\n",
    "print(new_rec.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([new_rec, new_new_rec]) # etc.\n",
    "print(\"\\n\\nAll experiments with measured values: \")\n",
    "print(results.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
